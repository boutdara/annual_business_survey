{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe664a63",
   "metadata": {},
   "source": [
    "# ETL Report\n",
    "This Notebook serves as the ETL report for Group 2's assessment using the United States Census Bureau Annual Business Survey (ABS) APIs. The steps below are outlined to extract, transform, and load the four APIs for analysis.\n",
    "\n",
    "There are a total of four transformation processes, with one for each group member. Each process is noted with the individual group member's name.\n",
    "\n",
    "Before starting the processes, you will need to register an API key to access the datasets. It can be obtained by following the numbered directions at this link: https://www.census.gov/data/developers/guidance/api-user-guide.Help_&_Contact_Us.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9b01aa",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9f0cbec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following packages and libraries:\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas import json_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd4f24a",
   "metadata": {},
   "source": [
    "Once you have your API key, you will need to replace YOUR_API_KEY in each of the URLs below with your API key.\n",
    "\n",
    "When you run the four cells below, it will extract the data from the each of the APIs and read the data from a JSON into a dataframe using pandas. After that, the headers for each dataset will be created by utilizing the first row (index 0). Further details may be explained in-line.\n",
    "\n",
    "For Dataset 1, since some of our visualizations will use data from individual states, while other visualizations use the country as a whole, we need to make sure we can call the API for both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "970e8c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 1: Company Summary\n",
    "url1_state = requests.get('https://api.census.gov/data/2018/abscs?get=GEO_ID,NAME,STATE,NAICS2017,NAICS2017_LABEL,YIBSZFI,YIBSZFI_LABEL,SEX,SEX_LABEL,ETH_GROUP,ETH_GROUP_LABEL,RACE_GROUP,RACE_GROUP_LABEL,VET_GROUP,VET_GROUP_LABEL,EMPSZFI,EMPSZFI_LABEL,YEAR,EMP,EMP_F,PAYANN,PAYANN_F&for=state:*&key=YOUR_API_KEY')\n",
    "conv1_state = url1_state.json()\n",
    "df1_state = pd.DataFrame(conv1_state)\n",
    "\n",
    "df1_state_header = df1_state.iloc[0] #Grab the first row for the header\n",
    "df1_state = df1_state[1:] #Take the data less the header row\n",
    "df1_state.columns = df1_state_header #Set the header row as the df header\n",
    "df1_state = df1_state.astype({'PAYANN': float, 'EMP': float}) #Get payroll and number of employees as number values\n",
    "\n",
    "# Unhash the line below to view the table:\n",
    "#df1_state\n",
    "\n",
    "url1_us = requests.get('https://api.census.gov/data/2018/abscs?get=GEO_ID,NAME,STATE,NAICS2017,NAICS2017_LABEL,YIBSZFI,YIBSZFI_LABEL,SEX,SEX_LABEL,ETH_GROUP,ETH_GROUP_LABEL,RACE_GROUP,RACE_GROUP_LABEL,VET_GROUP,VET_GROUP_LABEL,EMPSZFI,EMPSZFI_LABEL,YEAR,EMP,EMP_F,PAYANN,PAYANN_F&for=us:*&key=YOUR_API_KEY')\n",
    "conv1_us = url1_us.json()\n",
    "df1_us = pd.DataFrame(conv1_us)\n",
    "\n",
    "df1_us_header = df1_us.iloc[0] \n",
    "df1_us = df1_us[1:] \n",
    "df1_us.columns = df1_us_header \n",
    "df1_us = df1_us.astype({'PAYANN': float, 'EMP': float})\n",
    "\n",
    "# Unhash the line below to view the table:\n",
    "#df1_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e7089337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 2: Characteristics of Businesses\n",
    "url2 = requests.get('https://api.census.gov/data/2018/abscb?get=QDESC,QDESC_LABEL,BUSCHAR,BUSCHAR_LABEL,SEX,SEX_LABEL,RCPSZFI,RCPSZFI_LABEL,FIRMPDEMP,FIRMPDEMP_PCT,RCPPDEMP,RCPPDEMP_PCT&for=us&key=YOUR_API_KEY')\n",
    "conv2 = url2.json()\n",
    "df2 = pd.DataFrame(conv2)\n",
    "\n",
    "df2_header = df2.iloc[0]\n",
    "df2 = df2[1:]\n",
    "df2.columns = df2_header\n",
    "\n",
    "# Unhash the line below to view the table:\n",
    "#df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054f5f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 3: Characteristics of Business Owners\n",
    "url3 = requests.get('https://api.census.gov/data/2018/abscbo?get=NAICS2017,NAICS2017_LABEL,OWNER_SEX,OWNER_SEX_LABEL,OWNER_ETH,OWNER_ETH_LABEL,OWNER_RACE,OWNER_RACE_LABEL,OWNER_VET,OWNER_VET_LABEL,OWNPDEMP,OWNPDEMP_F,QDESC,QDESC_LABEL,OWNCHAR,OWNCHAR_LABEL,YEAR&for=us:*&key=YOUR_API_KEY')\n",
    "conv3 = url3.json()\n",
    "df3 = pd.DataFrame(conv3)\n",
    "\n",
    "df3_header = df3.iloc[0]\n",
    "df3 = df3[1:] \n",
    "df3.columns = df3_header\n",
    "\n",
    "# Unhash the line below to view the table:\n",
    "#df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afccaebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 4: Technology Characteristics of Businesses\n",
    "url4 = requests.get('https://api.census.gov/data/2018/abstcb?get=GEO_ID,NAME,FIRMPDEMP,TECHUSE,TECHUSE_LABEL,NSFSZFI,NSFSZFI_LABEL,FACTORS_P,FACTORS_P_LABEL&for=us:*&key=YOUR_API_KEY')\n",
    "conv4 = url4.json()\n",
    "df4 = pd.DataFrame(conv4)\n",
    "\n",
    "df4_header = df4.iloc[0]\n",
    "df4 = df4[1:] \n",
    "df4.columns = df4_header\n",
    "\n",
    "# Unhash the line below to view the table:\n",
    "#df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0d6d2d",
   "metadata": {},
   "source": [
    "# Data Transformation\n",
    "As stated before, the following data transformations are specific to the individual, which means that syntax and methods will vary between each person. Supplemental markdowns and in-line comments will be used to explain the transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464fea41",
   "metadata": {},
   "source": [
    "# Douglas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d732af3",
   "metadata": {},
   "source": [
    "Our first set of visualizations aims at looking into how much payroll is dedicated to different racial groups by state and by business category. However, since our data only makes up a survey of businesses in the United States, the raw payroll values in our dataset will probably be misleading. So, not only do we need to filter our data down to get exactly what we want, we also need to mutate our data to get the proper values to analyse.\n",
    "\n",
    "We also need to be wary of missing data within the dataset. The variables 'PAYROLL_F' and 'EMP_F', which stand for payroll_flag and employee_flag, respectively, are indicator variables to tell us not only whether or not there is missing data, but why. We want the rows with no flag, which indicates there being nothing wrong with our data.\n",
    "\n",
    "We now need to make sure that the only break out category included within our data is whichever racial group we want to highlight. So, we need to make sure every other category, ethnic group, sex, veteran status, firm size, number of years in business, and business type, needs to be set to include all categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ac1568",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df1_state[df1_state['PAYANN_F'].isna()==True]\n",
    "df_filtered = df_filtered[df_filtered['EMP_F'].isna()==True]\n",
    "df_filtered = df_filtered[df_filtered['EMPSZFI'] == '001']\n",
    "df_filtered = df_filtered[df_filtered['NAICS2017_LABEL'] == 'Total for all sectors']\n",
    "df_filtered = df_filtered[df_filtered['YIBSZFI_LABEL'] == 'All firms']\n",
    "df_filtered = df_filtered[df_filtered['SEX'] == '001']\n",
    "df_filtered = df_filtered[filtered['VET_GROUP'] == '001']\n",
    "df_filtered = df_filtered[filtered['ETH_GROUP'] == '001']\n",
    "df_black = df_filtered[df_filtered['RACE_GROUP_LABEL'] == 'Black or African American']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134e2120",
   "metadata": {},
   "source": [
    "For the sake of the visualization we want to make, we need to repeat this process, but instead of breaking into race, we want to include all businesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66a9bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total  = df_filtered[df_filtered['RACE_GROUP_LABEL'] == 'Total']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab51adc",
   "metadata": {},
   "source": [
    "Now, we can select the specific columns we need to build our visualizations from each dataset. The columns we need are 'NAME', 'PAYANN', and 'EMP'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc8ceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b = df_black[['NAME', 'PAYANN', 'EMP']]\n",
    "\n",
    "df_t = df_total[['NAME', 'PAYANN', 'EMP']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0182b957",
   "metadata": {},
   "source": [
    "From here, we want to create our new variable: pay per employee. We will do this by dividing the payroll column by the employee column, converting it into a list, and then adding it back into the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00bb222",
   "metadata": {},
   "outputs": [],
   "source": [
    "payroll_employee = df_b['PAYANN']/df_b['EMP']\n",
    "\n",
    "payroll_emp = payroll_employee.tolist()\n",
    "\n",
    "df_b.insert(3, \"Pay per Employee\", payroll_employee)\n",
    "\n",
    "payroll_employee = df_t['PAYANN']/df_t['EMP']\n",
    "\n",
    "payroll_emp = payroll_employee.tolist()\n",
    "\n",
    "df_b1.insert(3, \"Pay per Employee\", payroll_employee)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9febd1",
   "metadata": {},
   "source": [
    "Finally, we can merge these two datasets together using an inner join on the 'NAME' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f996c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b_merged = pd.merge(df_b, df_t, how = 'inner', on = 'NAME', suffixes = ('_black', '_total'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e23a61",
   "metadata": {},
   "source": [
    "Using this DataFrame, we can build our visualization comparing payroll per employee for black owned businesses with the payroll per employee of businesses overall by state.\n",
    "\n",
    "Now, we want to do essentially the exact same process, but instead of examining states, we will examine business type. For this, we use 'df1_us' instead of 'df1_state'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3598bc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df1_us[df1_us['PAYANN_F'].isna()==True]\n",
    "df_filtered = df_filtered[df_filtered['EMP_F'].isna()==True]\n",
    "df_filtered = df_filtered[df_filtered['EMPSZFI'] == '001']\n",
    "df_filtered = df_filtered[df_filtered['NAICS2017_LABEL'] != 'Total for all sectors']\n",
    "df_filtered = df_filtered[df_filtered['YIBSZFI_LABEL'] == 'All firms']\n",
    "df_filtered = df_filtered[df_filtered['SEX'] == '001']\n",
    "df_filtered = df_filtered[filtered['VET_GROUP'] == '001']\n",
    "df_filtered = df_filtered[filtered['ETH_GROUP'] == '001']\n",
    "df_black = df_filtered[df_filtered['RACE_GROUP_LABEL'] == 'Black or African American']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35f215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total  = df_filtered[df_filtered['RACE_GROUP_LABEL'] == 'Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c210a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b = df_black[['NAICS2017_LABEL', 'PAYANN', 'EMP']]\n",
    "\n",
    "df_t = df_total[['NAICS2017_LABEL', 'PAYANN', 'EMP']]\n",
    "\n",
    "payroll_employee = df_b['PAYANN']/df_b['EMP']\n",
    "\n",
    "payroll_emp = payroll_employee.tolist()\n",
    "\n",
    "df_b.insert(3, \"Pay per Employee\", payroll_employee)\n",
    "\n",
    "payroll_employee = df_t['PAYANN']/df_t['EMP']\n",
    "\n",
    "payroll_emp = payroll_employee.tolist()\n",
    "\n",
    "df_t.insert(3, \"Pay per Employee\", payroll_employee)\n",
    "\n",
    "df_b_merged = pd.merge(df_b, df_t, how = 'inner', on = 'NAME', suffixes = ('_black', '_total'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed104ee",
   "metadata": {},
   "source": [
    "For our second set of visualizations, we are going to do essentially the same thing, but instead we are going to look at veteran owned businesses. So, we will include all race categories, and compare veteran owned businesses with overall businesses and payroll per employee by state and industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307c5dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df1_state[df1_state['PAYANN_F'].isna()==True]\n",
    "df_filtered = df_filtered[df_filtered['EMP_F'].isna()==True]\n",
    "df_filtered = df_filtered[df_filtered['EMPSZFI'] == '001']\n",
    "df_filtered = df_filtered[df_filtered['NAICS2017_LABEL'] == 'Total for all sectors']\n",
    "df_filtered = df_filtered[df_filtered['YIBSZFI_LABEL'] == 'All firms']\n",
    "df_filtered = df_filtered[df_filtered['RACE_GROUP_LABEL'] == 'Total']\n",
    "df_filtered = df_filtered[df_filtered['SEX'] == '001']\n",
    "df_filtered = df_filtered[filtered['ETH_GROUP'] == '001']\n",
    "df_veteran = df_filtered[filtered['VET_GROUP'] == '002']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae883af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total  = df_filtered[df_filtered['VET_GROUP'] == '001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bcd1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = df_veteran[['NAME', 'PAYANN', 'EMP']]\n",
    "\n",
    "df_t = df_total[['NAME', 'PAYANN', 'EMP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e82a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = df_v[['NAME', 'PAYANN', 'EMP']]\n",
    "\n",
    "df_t = df_total[['NAME', 'PAYANN', 'EMP']]\n",
    "\n",
    "payroll_employee = df_v['PAYANN']/df_v['EMP']\n",
    "\n",
    "payroll_emp = payroll_employee.tolist()\n",
    "\n",
    "df_b.insert(3, \"Pay per Employee\", payroll_employee)\n",
    "\n",
    "payroll_employee = df_t['PAYANN']/df_t['EMP']\n",
    "\n",
    "payroll_emp = payroll_employee.tolist()\n",
    "\n",
    "df_t.insert(3, \"Pay per Employee\", payroll_employee)\n",
    "\n",
    "df_v_merged = pd.merge(df_v, df_t, how = 'inner', on = 'NAME', suffixes = ('_veteran', '_total'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a801520b",
   "metadata": {},
   "source": [
    "And again, we alter the process slightly for the business type as opposed to states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef976b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df1_us[df1_us['PAYANN_F'].isna()==True]\n",
    "df_filtered = df_filtered[df_filtered['EMP_F'].isna()==True]\n",
    "df_filtered = df_filtered[df_filtered['EMPSZFI'] == '001']\n",
    "df_filtered = df_filtered[df_filtered['NAICS2017_LABEL'] != 'Total for all sectors']\n",
    "df_filtered = df_filtered[df_filtered['YIBSZFI_LABEL'] == 'All firms']\n",
    "df_filtered = df_filtered[df_filtered['RACE_GROUP_LABEL'] == 'Total']\n",
    "df_filtered = df_filtered[df_filtered['SEX'] == '001']\n",
    "df_filtered = df_filtered[filtered['ETH_GROUP'] == '001']\n",
    "df_veteran = df_filtered[filtered['VET_GROUP'] == '002']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3067e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total  = df_filtered[df_filtered['VET_GROUP'] == '001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a25088",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = df_veteran[['NAICS2017_LABEL', 'PAYANN', 'EMP']]\n",
    "\n",
    "df_t = df_total[['NAICS2017_LABEL', 'PAYANN', 'EMP']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfe10a4",
   "metadata": {},
   "source": [
    "# Nicole\n",
    "Nicole sought to answer the following questions:\n",
    "1. How many businesses are female-owned for each revenue level?\n",
    "2. What percentage of businesses are owned by non-US citizens and those born outside of the United States?\n",
    "\n",
    "In Dataset 2, she was examining businesses with only one owner (where 'BUSCHAR' equals 'BQ'), so she had to filter out 'SEX_LABEL' so that there were only 'Male' and 'Female' variables in the column. Including 'Total' and 'Equally male/female' in the data makes no sense for the parameters specified and would skew the results.\n",
    "\n",
    "Dataset 3 was filtered by birth ('O11') and citizenship ('O12') status. The totals ('EJ' and 'EN') were excluded as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f81dbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 2\n",
    "filter_sex = df2.loc[(df2['BUSCHAR'] == 'BQ') & (df2['RCPSZFI_LABEL'] != 'All firms') & (df2['SEX_LABEL'] != 'Total') & (df2['SEX_LABEL'] != 'Equally male/female')]\n",
    "\n",
    "# Dataset 3\n",
    "filter_born = df3.loc[(df3['QDESC'] == 'O11') & (df3['OWNCHAR'] != 'EJ')]\n",
    "\n",
    "filter_citizen = df3.loc[(df3['QDESC'] == 'O12') & (df3['OWNCHAR'] != 'EN')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad94623c",
   "metadata": {},
   "source": [
    "# Chris\n",
    "Chris examined the trends in both education levels and ages of business owners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c443fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "YIB_EMP = df1_us[['YIBSZFI','EMP']] # isolate years-in-business and number-of-employees\n",
    "YIB_EMP = YIB_EMP.drop(YIB_EMP.index[YIB_EMP['YIBSZFI'] == '001']) # REMOVE specific value in a column where code 001 meant \"all firms\" which is useless to us\n",
    "YIB_EMP = YIB_EMP.replace({'YIBSZFI': {'311': '<2', '318': '2-3', '319': '4-5', '321':'6-10','322':'11-15','323':'16+'}}) # replace value codes with values that indicate the year ranges\n",
    "YIB_EMP['EMP'] = YIB_EMP['EMP'].astype(int) # change EMP type to integer\n",
    "YIB_EMP = YIB_EMP.rename(columns={'YIBSZFI':'Years In Business','EMP':'Number of Employees'}) # renamed columns\n",
    "YIB_EMP = YIB_EMP.groupby('Years In Business') # grouped all 'Years In Business' values\n",
    "YIB_EMP = YIB_EMP.mean() # calculated the average number of employees\n",
    "YIB_EMP # display 'Years In Business' and 'Number of Employees'\n",
    "\n",
    "# Owner's Education Level\n",
    "owner_main = df1_us[['QDESC','QDESC_LABEL','OWNCHAR']] # filter the columns needed\n",
    "edu = owner_main[(owner_main['QDESC'] == 'O07')] # sort to where QDESC only shows educational section\n",
    "edu = edu.drop(['QDESC','QDESC_LABEL'], axis=1) # drops to show only the OWNCHAR educational values\n",
    "edu = edu.drop(edu.index[edu['OWNCHAR'] == 'DS3']) # drops 'Professional degree beyond a bachelor's degree'\n",
    "edu = edu.drop(edu.index[edu['OWNCHAR'] == 'DT']) # drops 'Total reporting'\n",
    "edu = edu.drop(edu.index[edu['OWNCHAR'] == 'DU']) # drops 'Item not reported'\n",
    "edu = edu.replace({'OWNCHAR': {'DM': '>HS', 'DN': 'HS/GED', 'DO': 'Tech/Trade', 'DP':'Some College','DQ':'Associate','DR':'Bachelors','DS1':'Masters','DS2':'Doctorate'}}) # rename generic value codes to actual educational values\n",
    "edu = edu.rename(columns={'OWNCHAR':'Highest Education Obtained'}) # renamed columns\n",
    "edu\n",
    "\n",
    "# Owner's Age\n",
    "age = owner_main[(owner_main['QDESC'] == 'O09')]  # sort to where QDESC only shows age section\n",
    "age = age.drop(['QDESC','QDESC_LABEL'], axis=1) # drops to show only the OWNCHAR age values\n",
    "age = age.drop(age.index[age['OWNCHAR'] == 'EF']) # drops 'Total reporting'\n",
    "age = age.drop(age.index[age['OWNCHAR'] == 'EG']) # drops 'Item not reported'\n",
    "age = age.replace({'OWNCHAR': {'DZ': '<25', 'EA': '25-34', 'EB': '35-44', 'EC':'45-54','ED':'55-64','EE':'65+'}}) # rename generic value codes to actual age values\n",
    "age = age.rename(columns={'OWNCHAR':'Age Range'}) # renamed columns\n",
    "age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d4139e",
   "metadata": {},
   "source": [
    "# Dan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecb256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter down Company Summary Dataframe for only employee firm fize, number of employeer firms and NAICS code\n",
    "EMPSZFI_Num = df1_us[['EMPSZFI', 'FIRMPDEMP','NAICS2017']]\n",
    "#Since we are only looking for firm size totals for the entire country set NAICS code to only 00 and anf filter out firm size for all firms and no employees\n",
    "EMPSZFI_Num = EMPSZFI_Num[EMPSZFI_Num.NAICS2017 == '00']\n",
    "EMPSZFI_Num = EMPSZFI_Num.drop(EMPSZFI_Num.index[EMPSZFI_Num['EMPSZFI'] == '001'])\n",
    "EMPSZFI_Num = EMPSZFI_Num.drop(EMPSZFI_Num.index[EMPSZFI_Num['EMPSZFI'] == '611'])\n",
    "EMPSZFI_Num = EMPSZFI_Num.replace({'EMPSZFI': {'612': 'Firms with 1 to 4 employees', '620': 'Firms with 5 to 9 employees', '630': 'Firms with 10 to 19 employees', '641': 'Firms with 20 to 49 employees', '642': 'Firms with 50 to 99 employees', '651': 'Firms with 100 to 249 employees', '652': 'Firms with 250 to 499 employees', '657': 'Firms with 500 employees or more'}})\n",
    "EMPSZFI_Num\n",
    "\n",
    "#Filter down company Technology for NSFSZFI, Factors P, Factors P lable, and number of firms\n",
    "new = df4[['NSFSZFI','FACTORS_P','FACTORS_P_LABEL','FIRMPDEMP']]\n",
    "#Since we are looking at only issues related to the use of cloud technology, filter Factor P to show only that\n",
    "new = new[new['FACTORS_P_LABEL'].str.contains('Cloud', na = False)]\n",
    "new = new[new.NSFSZFI == '001']\n",
    "#Drop Factors where cloud wasnt an issue, wasnt applicable, and total reporting\n",
    "new = new.drop(new.index[new['FACTORS_P'] == '00'])\n",
    "new = new.drop(new.index[new['FACTORS_P'] == 'T2E36R99'])\n",
    "new = new.drop(new.index[new['FACTORS_P'] == 'T2E36R10'])\n",
    "new = new.drop(new.index[new['FACTORS_P'] == 'T2E36R09'])\n",
    "new['FIRMPDEMP'] = new['FIRMPDEMP'].astype(int)\n",
    "new = new.sort_values(by = 'FIRMPDEMP', ascending = True)\n",
    "new = new.replace({'FACTORS_P': {'T2E36R04': 'Required data not reliable', 'T2E36R03': 'Lacked acces to required data', 'T2E36R06': 'Laws and regulations', 'T2E36R02': 'Technology was not mature', 'T2E36R05': 'Lacked access to human capital and talent', 'T2E36R08': 'Lacked access to capital', 'T2E36R07': 'Saftey and security concerns', 'T2E36R01': 'Technology too expensive'}})\n",
    "new\n",
    "\n",
    "#filter down company technology for number of firms, Techuse,Technuse label, and number of firms\n",
    "new1 = df4[['NSFSZFI','TECHUSE','TECHUSE_LABEL','FIRMPDEMP']]\n",
    "#Since we want totals for all sectors filter NSFSZFI for 00\n",
    "new1 = new1.drop(new1.index[new1['TECHUSE'] == '00'])\n",
    "#Since we want to see only where companies did not use a technology filter Techuse/Techuse label for 001\n",
    "new1 = new1[new1.NSFSZFI == '001']\n",
    "new1 = new1[new1['TECHUSE_LABEL'].str.contains('Did not use', na = False)]\n",
    "new1['FIRMPDEMP'] = new1['FIRMPDEMP'].astype(int)\n",
    "new1 = new1.sort_values(by = 'FIRMPDEMP', ascending = True)\n",
    "new1 = new1.replace({'TECHUSE': {'T3E03B01': 'Specialized Software', 'T2E03B01': 'Cloud-Based', 'T5E03B01': 'Specialized Equipment', 'T1E03B01': 'Artificial Intelligence', 'T4E03B01': 'Robotics'}})\n",
    "new1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
